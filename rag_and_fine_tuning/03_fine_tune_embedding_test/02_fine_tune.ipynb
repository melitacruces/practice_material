{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d28930a-8b8b-44e6-8097-c99375bf37c9",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370e0d2-1e9c-417f-9387-e28a5f090475",
   "metadata": {},
   "source": [
    "En este notebook, ajustamos un sentencetransformers embedding model de código abierto con nuestro conjunto de datos generado sintéticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340211a-db64-458f-b3fb-4b87f09ab743",
   "metadata": {},
   "source": [
    "### Cargar modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd53aa4c-b83b-41a3-9b73-498aca71e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70df8f69-9d40-4467-9755-5582b4ca5178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-small-en\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3502aaba-3e8a-42a6-9665-9d59304e798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0ab4-6687-4b54-aff7-b30aa96f3698",
   "metadata": {},
   "source": [
    "### Definir dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad17db1-e4b6-4c54-9242-905fb9cd9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26aa72e-c158-4d6c-862f-bb555e5e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FPATH = './data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = './data/val_dataset.json'\n",
    "\n",
    "# usamos un tamaño de lote muy pequeño para ejecutar este ejemplo de prueba en una máquina local\n",
    "# normalmente debería ser mucho más grande\n",
    "\n",
    "BATCH_SIZE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2713df64-b708-48f9-8a0a-505ee24ec381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07e006a-9a08-4961-b639-66a7a65bc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "examples = []\n",
    "for query_id, query in queries.items():\n",
    "    try:\n",
    "        if query_id in relevant_docs:\n",
    "            node_id = relevant_docs[query_id][0]\n",
    "            text = corpus[node_id]\n",
    "            example = InputExample(texts=[query, text])\n",
    "            examples.append(example)\n",
    "        else:\n",
    "            print(f\"Query ID {query_id} not found in relevant_docs dictionary.\")\n",
    "    except KeyError:\n",
    "        print(f\"Query ID {query_id} not found in relevant_docs dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b7f2f2-0012-4ec7-8f44-1909d42c84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    examples, batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8acef2-8618-4afa-84e0-cd959d181208",
   "metadata": {},
   "source": [
    "### Definir pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d643c3f-563a-44ae-a4aa-6a5fd8780ff9",
   "metadata": {},
   "source": [
    "**MultipleNegativesRankingLoss** es una gran función de pérdida si solo tiene pares positivos, por ejemplo, solo pares de textos similares como pares de paráfrasis, pares de preguntas duplicadas, pares de (consulta, respuesta) o pares de (idioma_origen, idioma_destino).\n",
    "\n",
    "Esta función de pérdida funciona muy bien para entrenar modelos de embeddings para configuraciones RAG en las que tiene pares positivos (por ejemplo, (consulta, documento_relevante)), ya que tomará muestras en cada lote de n-1 documentos negativos de forma aleatoria.\n",
    "\n",
    "El rendimiento suele aumentar al aumentar el tamaño de los lotes.\n",
    "\n",
    "Para obtener más detalles, consulte:\n",
    "* [docs](https://www.sbert.net/docs/package_reference/losses.html)\n",
    "* [paper]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4e6b0f-8ffd-4f40-bbc8-bb307c32e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "928eec1f-0f47-4bac-9189-7b791e81024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95044745-c271-40b3-a6d9-dd646ab281de",
   "metadata": {},
   "source": [
    "### Definir evaluador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa016f4-ede5-4cfa-94d1-2449321a6ac8",
   "metadata": {},
   "source": [
    "Configuramos un evaluador con nuestra división de valores del conjunto de datos para monitorear qué tan bien se está desempeñando el modelo de incorporación durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4cb4df8-d12b-4956-85d5-447a24331cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ab1591-ce7e-4990-a708-9b22a7ce0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5deb95-6d9a-4da8-ba46-f0317b12d6df",
   "metadata": {},
   "source": [
    "### Ejecutar entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec69ca-21b0-4005-9e62-aef1393c4e6d",
   "metadata": {},
   "source": [
    "El ciclo de entrenamiento es muy sencillo de intensificar gracias a la API de entrenamiento de modelos de alto nivel de SentenceTransformers.\n",
    "Todo lo que tenemos que hacer es conectar el cargador de datos, la función de pérdida y el evaluador que definimos en las celdas anteriores (junto con un par de configuraciones menores adicionales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99ff9b09-c191-4ac0-a89e-629031e648d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo durante muy pocas epochs en este ejemplo de prueba\n",
    "# normalmente este valor debería ser mayor para obtener un mejor rendimiento\n",
    "\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b6afdf-87d6-40be-b6fd-36f89dbb3612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e63d0eacfce4a7285a9ccb0604c877d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d1dfd0575944499a0004a39bae17a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25862752176f442280102e2b0a2dd27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbae3b529bf74475842fe370ac9b05c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives = [(loader, loss)],\n",
    "    epochs = EPOCHS,\n",
    "    warmup_steps = warmup_steps,\n",
    "    output_path ='exp_finetune',\n",
    "    show_progress_bar = True,\n",
    "    evaluator = evaluator, \n",
    "    evaluation_steps = 50,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
