{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fe17dc-eaca-49ae-81b8-8c372bff4fb8",
   "metadata": {},
   "source": [
    "# Custom Evaluation with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13376312-ee85-470c-bb8a-ec13d6c38b2f",
   "metadata": {},
   "source": [
    "En esta caso, se evaluaron 3 modelos de embeddings:\n",
    "\n",
    "1. proprietary OpenAI embedding\n",
    "2. open source `BAAI/bge-small-en`\n",
    "3. our finetuned embedding model\n",
    "\n",
    "Consideramos 2 métricas de evaluación:\n",
    "\n",
    "1. a simple custom **hit rate** metric\n",
    "2. using `InformationRetrievalEvaluator` from sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f249133-d7ca-42e8-ad41-c5ef8fe5849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from llama_index.embeddings import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b4619-4a01-427e-97f3-ec7cac6d2bfd",
   "metadata": {},
   "source": [
    "### Cargar data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591bd3a-8be4-4596-acb8-d9d007239c32",
   "metadata": {},
   "source": [
    "Primero se debe carcar el dataset geneardo automáticamente de nuestros corpus (without having access to any labellers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e73cb5c7-a71c-4e70-ba24-ce196e7177af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FPATH = './data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = './data/val_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5a85bae-0f40-4d24-b96f-a5f884893310",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8232ec0e-40bf-4910-bdad-cca9d7de0619",
   "metadata": {},
   "source": [
    "### Definir función de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25744f5d-cd89-4f63-b1c9-238519b74bc8",
   "metadata": {},
   "source": [
    "**Opción 1**: Utilizamos una métrica simple de **tasa de aciertos** para la evaluación:\n",
    "* para cada par (query, relevant)\n",
    "* recuperamos los documentos con la query\n",
    "* es un **acierto** si los resultados contienen el relevant_doc relevante.\n",
    "\n",
    "Este enfoque es muy simple e intuitivo, y podemos aplicarlo tanto al modelo de embeddings OpenAI como a nuestros modelos de incrustación de código abierto y \"fine-tuneados\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75e79771-fe51-44a0-807f-ee9697064ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    dataset,\n",
    "    embed_model,\n",
    "    top_k = 5,\n",
    "    verbose=False,\n",
    "):\n",
    "    corpus = dataset['corpus']\n",
    "    queries = dataset['queries']\n",
    "    relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(embed_model = embed_model)\n",
    "    nodes = [TextNode(id_ = id_, text = text) for id_, text in corpus.items()] \n",
    "    index = VectorStoreIndex(\n",
    "        nodes, \n",
    "        service_context = service_context, \n",
    "        show_progress = True\n",
    "    )\n",
    "    retriever = index.as_retriever(similarity_top_k = top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
    "        \n",
    "        eval_result = {\n",
    "            'is_hit': is_hit,\n",
    "            'retrieved': retrieved_ids,\n",
    "            'expected': expected_id,\n",
    "            'query': query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282f2b8-3486-4e11-b314-4c2c52d2ea02",
   "metadata": {},
   "source": [
    "**Opción 2**: Usamos el `InformationRetrievalEvaluator` de sentence_transformers.\n",
    "\n",
    "Esto proporciona un conjunto de métricas más completo, pero solo podemos ejecutarlo en los modelos compatibles con los sentencetransformers (el de código abierto y nuestro modelo \"fine-tuneado\", **no** el modelo de incrustación de OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bce34cd-d51d-44c4-900b-9bded5e1ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def evaluate_st(\n",
    "    dataset,\n",
    "    model_id,\n",
    "    name,\n",
    "):\n",
    "    corpus = dataset['corpus']\n",
    "    queries = dataset['queries']\n",
    "    relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "    evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs, name=name)\n",
    "    model = SentenceTransformer(model_id)\n",
    "    return evaluator(model, output_path='results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0871d4-5a1a-4e5d-97d2-3fa9ae68af54",
   "metadata": {},
   "source": [
    "### Correr evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62183ec-ac63-4efc-9b9d-9a4c091bee22",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94922539-197e-459e-b5c0-16a515f2f100",
   "metadata": {},
   "source": [
    "Nota: esto puede tardar unos minutos en ejecutarse ya que tenemos que incrustar el corpus y las consultas. Gasta algunos créditos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0056d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aa63f1f-0d8d-4533-bc40-d7791c523bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d2689b0957452d964b2315bb92f9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd581f383b0940ac86151d5202d30cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ada = OpenAIEmbedding()\n",
    "ada_val_results = evaluate(val_dataset, ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cebfdf9-4d7b-417a-95df-01fcc5ac6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada = pd.DataFrame(ada_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20980c2f-c4ca-44f3-9c96-b5cef61c4f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9292929292929293"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_ada = df_ada['is_hit'].mean()\n",
    "hit_rate_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63f51d-3bf9-4360-8ff8-fd2593ea7eb5",
   "metadata": {},
   "source": [
    "### BAAI/bge-small-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d33e9fe-cddf-44f2-a300-ebe5dbf1dec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a497a3817c9344859dc0aa38928cfca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6738aa20425847ea8f312efbada2734f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bge = \"local:BAAI/bge-small-en\"\n",
    "bge_val_results = evaluate(val_dataset, bge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e633ef4-4681-45bf-9712-ef6abbc1769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bge = pd.DataFrame(bge_val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fb28364-ffa3-49af-b140-ffc8430756a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161616161616161"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_bge = df_bge['is_hit'].mean()\n",
    "hit_rate_bge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f18ee8ee-6437-4c69-aa00-153c81b798ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4626562105085016"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_st(val_dataset, \"BAAI/bge-small-en\", name='bge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c85066-27bd-4376-8f7b-b6cda3a99371",
   "metadata": {},
   "source": [
    "### Fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfb73b2c-5d69-42d5-9bba-bf5920e86b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaa13a5341c459a8c98d192e8090668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b4afbb7d7044779fe3d53394ded53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetuned = \"local:exp_finetune\"\n",
    "val_results_finetuned = evaluate(val_dataset, finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5861d26-ee50-47cb-9a34-3d9295a99754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetuned = pd.DataFrame(val_results_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ee59dda-b96b-44a8-836d-63970c2c4957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6717171717171717"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_finetuned = df_finetuned['is_hit'].mean()\n",
    "hit_rate_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ba92a7d-414c-4f25-9caa-f29922a25c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5324246590927099"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_st(val_dataset, \"exp_finetune\", name='finetuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2debfccd-542b-42b7-a603-4b4272435130",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76700270-cce3-4def-b545-bfefe94222b1",
   "metadata": {},
   "source": [
    "#### Tasa de aciertos (opción 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c66604a-a844-4efe-9d64-9aaccad2fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada['model'] = 'ada'\n",
    "df_bge['model'] = 'bge'\n",
    "df_finetuned['model'] = 'fine_tuned'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c04d3-1f29-4a91-a52d-561f4f498e7c",
   "metadata": {},
   "source": [
    "Podemos ver que ajustar nuestro pequeño modelo de embeddings de código abierto mejora drásticamente su calidad de recuperación (incluso acercándose a la calidad del modelo de embeddings de OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2d338ec-b130-4467-b6be-4a6bad60e205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.929293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bge</th>\n",
       "      <td>0.616162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_tuned</th>\n",
       "      <td>0.671717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              is_hit\n",
       "model               \n",
       "ada         0.929293\n",
       "bge         0.616162\n",
       "fine_tuned  0.671717"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat([df_ada, df_bge, df_finetuned])\n",
    "df_all.groupby('model').mean('is_hit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f87314-9790-40d7-9c72-ea1ccb4b789b",
   "metadata": {},
   "source": [
    "### InformationRetrievalEvaluator (opción 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19a777a0-a9c1-4d5c-9da6-fde91b5bb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_bge = pd.read_csv('results/Information-Retrieval_evaluation_bge_results.csv')\n",
    "df_st_finetuned = pd.read_csv('results/Information-Retrieval_evaluation_finetuned_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2bf70c-f3c5-4c68-b741-946e08d5567b",
   "metadata": {},
   "source": [
    "Podemos ver que el fine-tuning a un modelo de mebeddings mejora las métricas de manera consistente en todo el conjunto de métricas de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d30e52e-38e3-4164-9c31-26f47ac811db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>steps</th>\n",
       "      <th>cos_sim-Accuracy@1</th>\n",
       "      <th>cos_sim-Accuracy@3</th>\n",
       "      <th>cos_sim-Accuracy@5</th>\n",
       "      <th>cos_sim-Accuracy@10</th>\n",
       "      <th>cos_sim-Precision@1</th>\n",
       "      <th>cos_sim-Recall@1</th>\n",
       "      <th>cos_sim-Precision@3</th>\n",
       "      <th>cos_sim-Recall@3</th>\n",
       "      <th>...</th>\n",
       "      <th>dot_score-Recall@1</th>\n",
       "      <th>dot_score-Precision@3</th>\n",
       "      <th>dot_score-Recall@3</th>\n",
       "      <th>dot_score-Precision@5</th>\n",
       "      <th>dot_score-Recall@5</th>\n",
       "      <th>dot_score-Precision@10</th>\n",
       "      <th>dot_score-Recall@10</th>\n",
       "      <th>dot_score-MRR@10</th>\n",
       "      <th>dot_score-NDCG@10</th>\n",
       "      <th>dot_score-MAP@100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bge</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.065152</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.446601</td>\n",
       "      <td>0.495208</td>\n",
       "      <td>0.462656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_tuned</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414141</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.134343</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>0.075253</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.521216</td>\n",
       "      <td>0.577016</td>\n",
       "      <td>0.532397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            epoch  steps  cos_sim-Accuracy@1  cos_sim-Accuracy@3  \\\n",
       "model                                                              \n",
       "bge            -1     -1            0.358586            0.500000   \n",
       "fine_tuned     -1     -1            0.414141            0.590909   \n",
       "\n",
       "            cos_sim-Accuracy@5  cos_sim-Accuracy@10  cos_sim-Precision@1  \\\n",
       "model                                                                      \n",
       "bge                   0.555556             0.651515             0.358586   \n",
       "fine_tuned            0.671717             0.752525             0.414141   \n",
       "\n",
       "            cos_sim-Recall@1  cos_sim-Precision@3  cos_sim-Recall@3  ...  \\\n",
       "model                                                                ...   \n",
       "bge                 0.358586             0.166667          0.500000  ...   \n",
       "fine_tuned          0.414141             0.196970          0.590909  ...   \n",
       "\n",
       "            dot_score-Recall@1  dot_score-Precision@3  dot_score-Recall@3  \\\n",
       "model                                                                       \n",
       "bge                   0.358586               0.166667            0.500000   \n",
       "fine_tuned            0.414141               0.196970            0.590909   \n",
       "\n",
       "            dot_score-Precision@5  dot_score-Recall@5  dot_score-Precision@10  \\\n",
       "model                                                                           \n",
       "bge                      0.111111            0.555556                0.065152   \n",
       "fine_tuned               0.134343            0.671717                0.075253   \n",
       "\n",
       "            dot_score-Recall@10  dot_score-MRR@10  dot_score-NDCG@10  \\\n",
       "model                                                                  \n",
       "bge                    0.651515          0.446601           0.495208   \n",
       "fine_tuned             0.752525          0.521216           0.577016   \n",
       "\n",
       "            dot_score-MAP@100  \n",
       "model                          \n",
       "bge                  0.462656  \n",
       "fine_tuned           0.532397  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_st_bge['model'] = 'bge'\n",
    "df_st_finetuned['model'] = 'fine_tuned'\n",
    "df_st_all = pd.concat([df_st_bge, df_st_finetuned])\n",
    "df_st_all = df_st_all.set_index('model')\n",
    "df_st_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
