{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d28930a-8b8b-44e6-8097-c99375bf37c9",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370e0d2-1e9c-417f-9387-e28a5f090475",
   "metadata": {},
   "source": [
    "In this notebook, we finetune an opensource sentencetransformers embedding model on our synthetically generated dataset.\n",
    "En este notebook, ajustamos un modelo de integración de transformadores de oraciones de código abierto en nuestro conjunto de datos generado sintéticamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340211a-db64-458f-b3fb-4b87f09ab743",
   "metadata": {},
   "source": [
    "### Cargar modelo pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd53aa4c-b83b-41a3-9b73-498aca71e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70df8f69-9d40-4467-9755-5582b4ca5178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475b8d5c6bd64f8497215898fcb66a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92906e698a2f4a339503deca4e214401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f102a025467c4e98bc1471b4595747ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/90.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da11b67fad5e4cbc86113c387a9e301b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddd162902cf4aa0906e0951a9f6f003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202667c1ae934423869d86bf2430817e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5451c545d3b74539b44c325808bf6a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e631b78ae54b769ca4eadd5542a951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f57604ea1c4c70ab823dcb90b472ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf6abc49e6a4ea38ffebef6cab05eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a77503eb9341b19d4e2241ab80bdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6759acba0cc34e079131faa4b7893eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42b040770264adbb47f1ae80a6f1de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"BAAI/bge-small-en\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3502aaba-3e8a-42a6-9665-9d59304e798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0ab4-6687-4b54-aff7-b30aa96f3698",
   "metadata": {},
   "source": [
    "### Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad17db1-e4b6-4c54-9242-905fb9cd9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26aa72e-c158-4d6c-862f-bb555e5e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FPATH = './data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = './data/val_dataset.json'\n",
    "\n",
    "# Usamos un tamaño de lote muy pequeño para ejecutar este ejemplo de prueba en una máquina local.\n",
    "# Normalmente debería ser mucho más grande.\n",
    "\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2713df64-b708-48f9-8a0a-505ee24ec381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07e006a-9a08-4961-b639-66a7a65bc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "examples = []\n",
    "for query_id, query in queries.items():\n",
    "    node_id = relevant_docs[query_id][0]\n",
    "    text = corpus[node_id]\n",
    "    example = InputExample(texts=[query, text])\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b7f2f2-0012-4ec7-8f44-1909d42c84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    examples, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8acef2-8618-4afa-84e0-cd959d181208",
   "metadata": {},
   "source": [
    "### Definir pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d643c3f-563a-44ae-a4aa-6a5fd8780ff9",
   "metadata": {},
   "source": [
    "**MultipleNegativesRankingLoss** is a great loss function if you only have positive pairs, for example, only pairs of similar texts like pairs of paraphrases, pairs of duplicate questions, pairs of (query, response), or pairs of (source_language, target_language).\n",
    "\n",
    "This loss function works great to train embeddings for retrieval setups where you have positive pairs (e.g. (query, relevant_doc)) as it will sample in each batch n-1 negative docs randomly.\n",
    "\n",
    "The performance usually increases with increasing batch sizes.\n",
    "\n",
    "For more detals, see:\n",
    "* [docs](https://www.sbert.net/docs/package_reference/losses.html)\n",
    "* [paper]( \n",
    "\n",
    "**MultipleNegativesRankingLoss** es una gran función de pérdida si solo tiene pares positivos, por ejemplo, solo pares de textos similares como pares de paráfrasis, pares de preguntas duplicadas, pares de (consulta, respuesta) o pares de (idioma_origen, idioma_destino ).\n",
    "\n",
    "Esta función de pérdida funciona muy bien para entrenar incrustaciones para configuraciones de recuperación en las que tiene pares positivos (por ejemplo, (consulta, documento_relevante)), ya que tomará muestras en cada lote de n-1 documentos negativos de forma aleatoria.\n",
    "\n",
    "El rendimiento suele aumentar al aumentar el tamaño de los lotes.\n",
    "\n",
    "Para obtener más detalles, consulte:\n",
    "* [docs](https://www.sbert.net/docs/package_reference/losses.html)\n",
    "* [papel]("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4e6b0f-8ffd-4f40-bbc8-bb307c32e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "928eec1f-0f47-4bac-9189-7b791e81024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95044745-c271-40b3-a6d9-dd646ab281de",
   "metadata": {},
   "source": [
    "### Definir evaluador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa016f4-ede5-4cfa-94d1-2449321a6ac8",
   "metadata": {},
   "source": [
    "Configuramos un evaluador con nuestra división de valores del conjunto de datos para monitorear qué tan bien se está desempeñando el modelo de incorporación durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4cb4df8-d12b-4956-85d5-447a24331cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ab1591-ce7e-4990-a708-9b22a7ce0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5deb95-6d9a-4da8-ba46-f0317b12d6df",
   "metadata": {},
   "source": [
    "### Ejecutar entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec69ca-21b0-4005-9e62-aef1393c4e6d",
   "metadata": {},
   "source": [
    "The training loop is very straight forward to steup thanks to sentencetransformers' high-level model training API.\n",
    "All we need to do is plugging in the data loader, loss function, and evaluator that we defined in the previous cells (along with a couple of additional minor settings).\n",
    "\n",
    "El ciclo de entrenamiento es muy sencillo de intensificar gracias a la API de entrenamiento de modelos de alto nivel de SentenciaTransformers.\n",
    "Todo lo que tenemos que hacer es conectar el cargador de datos, la función de pérdida y el evaluador que definimos en las celdas anteriores (junto con un par de configuraciones menores adicionales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99ff9b09-c191-4ac0-a89e-629031e648d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo durante muy pocas épocas en este ejemplo de prueba.\n",
    "# Normalmente este valor debería ser mayor para obtener un mejor rendimiento.\n",
    "\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b6afdf-87d6-40be-b6fd-36f89dbb3612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c820ef6c204f3f89c20b770784cf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581838d4c82046939496a65e9fbaeeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee332e5549a4cf8a7c6f1eb2e634b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='exp_finetune',\n",
    "    show_progress_bar=True,\n",
    "    evaluator=evaluator, \n",
    "    evaluation_steps=50,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
