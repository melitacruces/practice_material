{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluación con Ragas y métodos avanzados de recuperación utilizando LangChain\n",
        "\n",
        "Vamos a aprovechar el marco de trabajo Ragas para las evaluaciones, ya que está convirtiéndose en un método estándar para evaluar (al menos en términos generales) sistemas RAG.\n",
        "\n",
        "[Ragas Repository](https://github.com/explodinggradients/ragas)\n",
        "\n",
        "[Ragas Documentation](https://docs.ragas.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BN13TZlSCv4"
      },
      "outputs": [],
      "source": [
        "%pip install langchain openai ragas arxiv pymupdf chromadb wandb tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "c33f7eee-b819-40bd-dc75-ce90721a6a94"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
        "\n",
        "# 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"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "### Recopilación de datos\n",
        "\n",
        "Se utilizarán artículos de Arxiv como contexto.\n",
        "\n",
        "Podemos recopilar estos documentos de manera bastante directa con el cargador de documentos `ArxivLoader` de LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTDNFXaBSO2j",
        "outputId": "3b24521d-5c6f-466b-d818-46ce68d359ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import ArxivLoader\n",
        "\n",
        "base_docs = ArxivLoader(query = \"Retrieval Augmented Generation\", load_max_docs = 5).load()\n",
        "len(base_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNPAWPgNSyGP",
        "outputId": "b2f80fc8-792c-489a-b8d4-9f98678c679a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Published': '2022-02-13', 'Title': 'A Survey on Retrieval-Augmented Text Generation', 'Authors': 'Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu', 'Summary': 'Recently, retrieval-augmented text generation attracted increasing attention\\nof the computational linguistics community. Compared with conventional\\ngeneration models, retrieval-augmented text generation has remarkable\\nadvantages and particularly has achieved state-of-the-art performance in many\\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\\ngeneration, and then it reviews notable approaches according to different tasks\\nincluding dialogue response generation, machine translation, and other\\ngeneration tasks. Finally, it points out some important directions on top of\\nrecent methods to facilitate future research.'}\n",
            "{'Published': '2023-12-09', 'Title': 'Context Tuning for Retrieval Augmented Generation', 'Authors': 'Raviteja Anantha, Tharun Bethi, Danil Vodianik, Srinivas Chappidi', 'Summary': \"Large language models (LLMs) have the remarkable ability to solve new tasks\\nwith just a few examples, but they need access to the right tools. Retrieval\\nAugmented Generation (RAG) addresses this problem by retrieving a list of\\nrelevant tools for a given task. However, RAG's tool retrieval step requires\\nall the required information to be explicitly present in the query. This is a\\nlimitation, as semantic search, the widely adopted tool retrieval method, can\\nfail when the query is incomplete or lacks context. To address this limitation,\\nwe propose Context Tuning for RAG, which employs a smart context retrieval\\nsystem to fetch relevant information that improves both tool retrieval and plan\\ngeneration. Our lightweight context retrieval model uses numerical,\\ncategorical, and habitual usage signals to retrieve and rank context items. Our\\nempirical results demonstrate that context tuning significantly enhances\\nsemantic search, achieving a 3.5-fold and 1.5-fold improvement in Recall@K for\\ncontext retrieval and tool retrieval tasks respectively, and resulting in an\\n11.6% increase in LLM-based planner accuracy. Additionally, we show that our\\nproposed lightweight model using Reciprocal Rank Fusion (RRF) with LambdaMART\\noutperforms GPT-4 based retrieval. Moreover, we observe context augmentation at\\nplan generation, even after tool retrieval, reduces hallucination.\"}\n",
            "{'Published': '2024-02-16', 'Title': 'Corrective Retrieval Augmented Generation', 'Authors': 'Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling', 'Summary': 'Large language models (LLMs) inevitably exhibit hallucinations since the\\naccuracy of generated texts cannot be secured solely by the parametric\\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\\ndocuments, raising concerns about how the model behaves if retrieval goes\\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\\nretrieval evaluator is designed to assess the overall quality of retrieved\\ndocuments for a query, returning a confidence degree based on which different\\nknowledge retrieval actions can be triggered. Since retrieval from static and\\nlimited corpora can only return sub-optimal documents, large-scale web searches\\nare utilized as an extension for augmenting the retrieval results. Besides, a\\ndecompose-then-recompose algorithm is designed for retrieved documents to\\nselectively focus on key information and filter out irrelevant information in\\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\\nRAG-based approaches. Experiments on four datasets covering short- and\\nlong-form generation tasks show that CRAG can significantly improve the\\nperformance of RAG-based approaches.'}\n",
            "{'Published': '2023-05-27', 'Title': 'Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In', 'Authors': 'Zichun Yu, Chenyan Xiong, Shi Yu, Zhiyuan Liu', 'Summary': \"Retrieval augmentation can aid language models (LMs) in knowledge-intensive\\ntasks by supplying them with external information. Prior works on retrieval\\naugmentation usually jointly fine-tune the retriever and the LM, making them\\nclosely coupled. In this paper, we explore the scheme of generic retrieval\\nplug-in: the retriever is to assist target LMs that may not be known beforehand\\nor are unable to be fine-tuned together. To retrieve useful documents for\\nunseen target LMs, we propose augmentation-adapted retriever (AAR), which\\nlearns LM's preferences obtained from a known source LM. Experiments on the\\nMMLU and PopQA datasets demonstrate that our AAR trained with a small source LM\\nis able to significantly improve the zero-shot generalization of larger target\\nLMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates\\nthat the preferences of different LMs overlap, enabling AAR trained with a\\nsingle source LM to serve as a generic plug-in for various target LMs. Our code\\nis open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.\"}\n",
            "{'Published': '2023-02-07', 'Title': 'Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories', 'Authors': 'Suyu Ge, Chenyan Xiong, Corby Rosset, Arnold Overwijk, Jiawei Han, Paul Bennett', 'Summary': 'In this paper we improve the zero-shot generalization ability of language\\nmodels via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves\\naugmentation documents from multiple information corpora (\"external memories\"),\\nwith the option to \"plug in\" new memory at inference time. We develop a joint\\nlearning mechanism that trains the augmentation component with latent labels\\nderived from the end retrieval task, paired with hard negatives from the memory\\nmixture. We instantiate the model in a zero-shot dense retrieval setting by\\naugmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains\\nstrong zero-shot retrieval accuracy on the eighteen tasks included in the\\nstandard BEIR benchmark. It outperforms systems that seek generalization from\\nincreased model parameters and computation steps. Our analysis further\\nillustrates the necessity of augmenting with mixture-of-memory for robust\\ngeneralization, the benefits of augmentation learning, and how MoMA utilizes\\nthe plug-in memory at inference time without changing its parameters. We plan\\nto open source our code.'}\n"
          ]
        }
      ],
      "source": [
        "for doc in base_docs:\n",
        "  print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "### Creación de un índice\n",
        "\n",
        "Se utilizará una estrategia de creación de índices que consiste en simplemente utilizar [`RecursiveCharacterTextSplitter`](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html) en nuestros documentos y embed cada uno en nuestro `VectorStore` utilizando `OpenAIEmbeddings()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\NITRO\\anaconda3\\envs\\ragas\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 250)\n",
        "\n",
        "docs = text_splitter.split_documents(base_docs)\n",
        "\n",
        "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnRzYx4c_2mZ",
        "outputId": "59d9bdd8-0414-4e8b-c285-bf3a2760e26a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4899"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyUh8EVI_6TZ",
        "outputId": "643fca9d-77c0-4296-d953-ec62d6de8954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "249\n"
          ]
        }
      ],
      "source": [
        "print(max([len(chunk.page_content) for chunk in docs]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f9kNIUUTxdT"
      },
      "source": [
        "Vamos a convertir nuestro vectorstore `Chroma` en un recuperador utilizando el método `.as_retriever()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bwbdftltT29h"
      },
      "outputs": [],
      "source": [
        "base_retriever = vectorstore.as_retriever(search_kwargs = {\"k\": 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBPZQUt4UBPl"
      },
      "source": [
        "Prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r0Pie4xqUCkW"
      },
      "outputs": [],
      "source": [
        "relevant_docs = base_retriever.get_relevant_documents(\"What is Retrieval Augmented Generation?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_CiHTD0UKj7",
        "outputId": "fab040cf-971f-440a-a6aa-93873c8e152f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(relevant_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "## Crear plantilla de prompts para RAG\n",
        "\n",
        "Configurar una plantilla de prompts que se utilizará para proporcionar al LLM los contextos necesarios, la consulta del usuario y las instrucciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "### CONTEXT\n",
        "{context}\n",
        "\n",
        "### QUESTION\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "### Configurar cadena de preguntas y respuestas\n",
        "\n",
        "Ahora podemos instanciar nuestra cadena básica de RAG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\NITRO\\anaconda3\\envs\\ragas\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | base_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "2520bf73-9e62-435c-a213-c26d0655a913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'response': AIMessage(content='RAG stands for Retrieval-Augmented Generation.'), 'context': [Document(page_content='seamlessly coupled with various RAG-based\\napproaches.\\nExperiments on four datasets\\ncovering short- and long-form generation tasks\\nshow that CRAG can significantly improve the\\nperformance of RAG-based approaches.1\\n1\\nIntroduction', metadata={'Authors': 'Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling', 'Published': '2024-02-16', 'Summary': 'Large language models (LLMs) inevitably exhibit hallucinations since the\\naccuracy of generated texts cannot be secured solely by the parametric\\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\\ndocuments, raising concerns about how the model behaves if retrieval goes\\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\\nretrieval evaluator is designed to assess the overall quality of retrieved\\ndocuments for a query, returning a confidence degree based on which different\\nknowledge retrieval actions can be triggered. Since retrieval from static and\\nlimited corpora can only return sub-optimal documents, large-scale web searches\\nare utilized as an extension for augmenting the retrieval results. Besides, a\\ndecompose-then-recompose algorithm is designed for retrieved documents to\\nselectively focus on key information and filter out irrelevant information in\\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\\nRAG-based approaches. Experiments on four datasets covering short- and\\nlong-form generation tasks show that CRAG can significantly improve the\\nperformance of RAG-based approaches.', 'Title': 'Corrective Retrieval Augmented Generation'}), Document(page_content='framework and named it Self-CRAG. Self-RAG\\nis an advanced RAG approach that introduces a\\ncritic model to decide whether to retrieve and which\\nretrieved document to be referred for generation. It\\nmeets our demand for deciding which action to be', metadata={'Authors': 'Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling', 'Published': '2024-02-16', 'Summary': 'Large language models (LLMs) inevitably exhibit hallucinations since the\\naccuracy of generated texts cannot be secured solely by the parametric\\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\\ndocuments, raising concerns about how the model behaves if retrieval goes\\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\\nretrieval evaluator is designed to assess the overall quality of retrieved\\ndocuments for a query, returning a confidence degree based on which different\\nknowledge retrieval actions can be triggered. Since retrieval from static and\\nlimited corpora can only return sub-optimal documents, large-scale web searches\\nare utilized as an extension for augmenting the retrieval results. Besides, a\\ndecompose-then-recompose algorithm is designed for retrieved documents to\\nselectively focus on key information and filter out irrelevant information in\\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\\nRAG-based approaches. Experiments on four datasets covering short- and\\nlong-form generation tasks show that CRAG can significantly improve the\\nperformance of RAG-based approaches.', 'Title': 'Corrective Retrieval Augmented Generation'})]}\n"
          ]
        }
      ],
      "source": [
        "question = \"What is RAG?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\": question})\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyazkAIu85KL"
      },
      "source": [
        "### Crear conjunto de datos de referencia utilizando gpt-3.5-turbo y gpt-4\n",
        "\n",
        "La idea es que se use LangChain para crear preguntas basadas en nuestros contextos y luego responder esas preguntas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V24T_gpPatAO"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "question_schema = ResponseSchema(\n",
        "    name = \"question\",\n",
        "    description = \"A question about the context.\"\n",
        ")\n",
        "\n",
        "question_response_schemas = [\n",
        "    question_schema,\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ebbmazGrdPap"
      },
      "outputs": [],
      "source": [
        "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)\n",
        "format_instructions = question_output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qorL4TPGXJQ7"
      },
      "outputs": [],
      "source": [
        "question_generation_llm = ChatOpenAI(model = \"gpt-3.5-turbo-16k\")\n",
        "\n",
        "bare_prompt_template = \"{content}\"\n",
        "bare_template = ChatPromptTemplate.from_template(template = bare_prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oPqC1_MXdRuh"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each context, create a question that is specific to the context. Avoid creating generic or general questions.\n",
        "\n",
        "question: a question about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "question\n",
        "\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template = qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context = docs[0],\n",
        "    format_instructions = format_instructions\n",
        ")\n",
        "\n",
        "question_generation_chain = bare_template | question_generation_llm\n",
        "\n",
        "response = question_generation_chain.invoke({\"content\": messages})\n",
        "output_dict = question_output_parser.parse(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFw9kyZd7eB",
        "outputId": "bbcf9e15-58be-4899-f102-6cae59c45eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question\n",
            "What is the main focus of the paper 'A Survey on Retrieval-Augmented Text Generation'?\n",
            "context\n",
            "{'page_content': 'A Survey on Retrieval-Augmented Text Generation\\nHuayang Li♥,∗\\nYixuan Su♠,∗\\nDeng Cai♦,∗\\nYan Wang♣,∗\\nLemao Liu♣,∗\\n♥Nara Institute of Science and Technology\\n♠University of Cambridge\\n♦The Chinese University of Hong Kong\\n♣Tencent AI Lab', 'metadata': {'Published': '2022-02-13', 'Title': 'A Survey on Retrieval-Augmented Text Generation', 'Authors': 'Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu', 'Summary': 'Recently, retrieval-augmented text generation attracted increasing attention\\nof the computational linguistics community. Compared with conventional\\ngeneration models, retrieval-augmented text generation has remarkable\\nadvantages and particularly has achieved state-of-the-art performance in many\\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\\ngeneration, and then it reviews notable approaches according to different tasks\\nincluding dialogue response generation, machine translation, and other\\ngeneration tasks. Finally, it points out some important directions on top of\\nrecent methods to facilitate future research.'}}\n"
          ]
        }
      ],
      "source": [
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dtASDdhLfd89"
      },
      "outputs": [],
      "source": [
        "%pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zolpr3CYeEYm",
        "outputId": "a7962cf2-4cdf-4c7a-b776-a0c2478042e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:32<00:00,  3.24s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "qac_triples = []\n",
        "\n",
        "for text in tqdm(docs[: 10]):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context = text,\n",
        "      format_instructions = format_instructions\n",
        "  )\n",
        "  response = question_generation_chain.invoke({\"content\": messages})\n",
        "  try:\n",
        "    output_dict = question_output_parser.parse(response.content)\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  output_dict[\"context\"] = text\n",
        "  qac_triples.append(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKBdQHK7Y2Vw",
        "outputId": "73c7d139-be2d-483f-9f70-b6c4aae91506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What are the advantages of retrieval-augmented text generation compared to conventional generation models?',\n",
              " 'context': Document(page_content='lemaoliu@gmail.com\\nAbstract\\nRecently, retrieval-augmented text generation\\nattracted increasing attention of the compu-\\ntational linguistics community.\\nCompared\\nwith conventional generation models, retrieval-', metadata={'Published': '2022-02-13', 'Title': 'A Survey on Retrieval-Augmented Text Generation', 'Authors': 'Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu', 'Summary': 'Recently, retrieval-augmented text generation attracted increasing attention\\nof the computational linguistics community. Compared with conventional\\ngeneration models, retrieval-augmented text generation has remarkable\\nadvantages and particularly has achieved state-of-the-art performance in many\\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\\ngeneration, and then it reviews notable approaches according to different tasks\\nincluding dialogue response generation, machine translation, and other\\ngeneration tasks. Finally, it points out some important directions on top of\\nrecent methods to facilitate future research.'})}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qac_triples[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vNB9Z2DrX2TC"
      },
      "outputs": [],
      "source": [
        "answer_generation_llm = ChatOpenAI(model = \"gpt-4-1106-preview\", temperature = 0)\n",
        "\n",
        "answer_schema = ResponseSchema(\n",
        "    name = \"answer\",\n",
        "    description = \"An answer to the question.\"\n",
        ")\n",
        "\n",
        "answer_response_schemas = [\n",
        "    answer_schema,\n",
        "]\n",
        "\n",
        "answer_output_parser = StructuredOutputParser.from_response_schemas(answer_response_schemas)\n",
        "format_instructions = answer_output_parser.get_format_instructions()\n",
        "\n",
        "qa_template = \"\"\"\\\n",
        "You are a University Professor creating a test for advanced students. For each question and context, create an answer.\n",
        "\n",
        "answer: a answer about the context.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "answer\n",
        "\n",
        "question: {question}\n",
        "context: {context}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template = qa_template)\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    context = qac_triples[0][\"context\"],\n",
        "    question = qac_triples[0][\"question\"],\n",
        "    format_instructions = format_instructions\n",
        ")\n",
        "\n",
        "answer_generation_chain = bare_template | answer_generation_llm\n",
        "\n",
        "response = answer_generation_chain.invoke({\"content\": messages})\n",
        "output_dict = answer_output_parser.parse(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-_lRR6fn5U",
        "outputId": "fb014a65-a56f-49be-8ecf-9ca5527aa803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "answer\n",
            "This paper aims to conduct a survey about retrieval-augmented text generation, highlighting the generic paradigm of this approach and reviewing notable methods across various NLP tasks such as dialogue response generation, machine translation, and other generation tasks, while also identifying important future research directions.\n"
          ]
        }
      ],
      "source": [
        "for k, v in output_dict.items():\n",
        "  print(k)\n",
        "  print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdH0e9rrAKd",
        "outputId": "629d8791-dedb-47c7-b5a0-adaa26f142cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [02:19<00:00, 15.52s/it]\n"
          ]
        }
      ],
      "source": [
        "for triple in tqdm(qac_triples):\n",
        "  messages = prompt_template.format_messages(\n",
        "      context = triple[\"context\"],\n",
        "      question = triple[\"question\"],\n",
        "      format_instructions = format_instructions\n",
        "  )\n",
        "  response = answer_generation_chain.invoke({\"content\": messages})\n",
        "  try:\n",
        "    output_dict = answer_output_parser.parse(response.content)\n",
        "  except Exception as e:\n",
        "    continue\n",
        "  triple[\"answer\"] = output_dict[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rrHXgH9Qs1ep"
      },
      "outputs": [],
      "source": [
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uAvGGTyXsoHQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\NITRO\\anaconda3\\envs\\ragas\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "ground_truth_qac_set = pd.DataFrame(qac_triples)\n",
        "ground_truth_qac_set[\"context\"] = ground_truth_qac_set[\"context\"].map(lambda x: str(x.page_content))\n",
        "ground_truth_qac_set = ground_truth_qac_set.rename(columns = {\"answer\": \"ground_truth\"})\n",
        "\n",
        "\n",
        "eval_dataset = Dataset.from_pandas(ground_truth_qac_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_FHUnAPVseB",
        "outputId": "1a907389-e62b-4686-b3d7-e8707acfbd47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'context', 'ground_truth'],\n",
              "    num_rows: 9\n",
              "})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8CaCUeBVu4l",
        "outputId": "72cbf3c8-c698-4682-821a-8566f36f6adb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What does this paper aim to conduct a survey about?',\n",
              " 'context': 'A Survey on Retrieval-Augmented Text Generation\\nHuayang Li♥,∗\\nYixuan Su♠,∗\\nDeng Cai♦,∗\\nYan Wang♣,∗\\nLemao Liu♣,∗\\n♥Nara Institute of Science and Technology\\n♠University of Cambridge\\n♦The Chinese University of Hong Kong\\n♣Tencent AI Lab',\n",
              " 'ground_truth': 'This paper aims to conduct a survey about retrieval-augmented text generation, highlighting the generic paradigm of this approach, reviewing notable methods across various tasks such as dialogue response generation and machine translation, and identifying important future research directions.'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c4bc64d47f2e4a239cf7156e7812887d",
            "b4a71cf676584200b46922fb976d1d50",
            "65f75f3d72cd415faffb32999893738d",
            "5367cbe7ca4d43b089ff0d5d7cd17d3c",
            "31390facfbeb455fa83067fc23d30718",
            "22fc25617c664e4aa02b7457832c1bef",
            "b556054df18d47aa8cb58ac482ca31bb",
            "0fff4a6672c848a38945e19101c46168",
            "de662cb67d054f08a15d191923d40369",
            "b53ebcf672a244978391cae559db5bf2",
            "f2de6a2c1f4b4a2fa5196028c0da0754"
          ]
        },
        "id": "Nhp5X4M8zqrm",
        "outputId": "7e3c36df-12a3-4ea7-a772-dc1e0bc61568"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 125.08ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7533"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset.to_csv(\"groundtruth_eval_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Al5cagr-rvL"
      },
      "source": [
        "### Evaluación de los conductos RAG\n",
        "\n",
        "Se puede cargar el archivo `.csv` directamente y así no generarlo nuevamente, descomenta el código a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QJhes58R66-P"
      },
      "outputs": [],
      "source": [
        "# from datasets import Dataset\n",
        "# eval_dataset = Dataset.from_csv(\"groundtruth_eval_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fAD8c_kthWc",
        "outputId": "e722498d-3179-4cf1-e206-29a27163ace5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'context', 'ground_truth'],\n",
              "    num_rows: 9\n",
              "})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqFYbjLK-6X7"
      },
      "source": [
        "### Evaluación usando Ragas\n",
        "\n",
        "Necesitamos crear un conjunto de datos con nuestras respuestas generadas y nuestros contextos, luego evaluar utilizando el marco de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1eBoHaf5t4w8"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    context_relevancy,\n",
        "    answer_correctness,\n",
        "    answer_similarity\n",
        ")\n",
        "\n",
        "from ragas.metrics.critique import harmfulness\n",
        "from ragas import evaluate\n",
        "\n",
        "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
        "  rag_dataset = []\n",
        "  for row in tqdm(eval_dataset):\n",
        "    answer = rag_pipeline.invoke({\"question\": row[\"question\"]})\n",
        "    rag_dataset.append(\n",
        "        {\"question\": row[\"question\"],\n",
        "         \"answer\": answer[\"response\"].content,\n",
        "         \"contexts\": [context.page_content for context in answer[\"context\"]],\n",
        "         \"ground_truths\": [row[\"ground_truth\"]]\n",
        "         }\n",
        "    )\n",
        "  rag_df = pd.DataFrame(rag_dataset)\n",
        "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
        "  return rag_eval_dataset\n",
        "\n",
        "def evaluate_ragas_dataset(ragas_dataset):\n",
        "  result = evaluate(\n",
        "    ragas_dataset,\n",
        "    metrics = [\n",
        "        context_precision,\n",
        "        faithfulness,\n",
        "        answer_relevancy,\n",
        "        context_recall,\n",
        "        context_relevancy,\n",
        "        answer_correctness,\n",
        "        answer_similarity\n",
        "    ],\n",
        "  )\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4c4Jd8G_lXY"
      },
      "source": [
        "Primero debemos crear el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7oXgcjkuopO",
        "outputId": "6db1a904-90a2-4e47-85da-a442ebdc56b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:28<00:00,  3.11s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "basic_qa_ragas_dataset = create_ragas_dataset(retrieval_augmented_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfzaFWEMZ5l_",
        "outputId": "60ca3e05-209a-4375-f24c-a23ad06e525e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'contexts', 'ground_truths'],\n",
              "    num_rows: 9\n",
              "})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_ragas_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vv1NsRGZ6m5",
        "outputId": "2ef4fbd9-011e-42b7-88d9-11c79974d87e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What does this paper aim to conduct a survey about?',\n",
              " 'answer': \"I don't know.\",\n",
              " 'contexts': ['retrieval. Acm Computing Surveys (CSUR), 44(1):1–\\n50.\\nDanqi Chen, Adam Fisch, Jason Weston, and Antoine\\nBordes. 2017. Reading Wikipedia to Answer Open-\\nDomain Questions. In Proceedings of the 55th An-',\n",
              "  'generation), PubHealth (Zhang et al., 2023a) (true-\\nor-false question), and Arc-Challenge (Bhaktha-\\nvatsalam et al., 2021) (multiple-choice question).\\n2In this study, Google Search API is utilized for searching.\\nPopQA\\nBio\\nPub\\nARC\\nMethod\\n(Accuracy)'],\n",
              " 'ground_truths': ['This paper aims to conduct a survey about retrieval-augmented text generation, highlighting the generic paradigm of this approach, reviewing notable methods across various tasks such as dialogue response generation and machine translation, and identifying important future research directions.']}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_ragas_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obbgw3im_n01"
      },
      "source": [
        "Guardar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "86761a36bdb04fed9f1dae6e74da54ce",
            "e079c0eb3d9c4ae3a40491f059a864f7",
            "d4bde97f3895450782030cad7808ea59",
            "1d17b8847ab34a1d8fc79430e8b64a12",
            "fb953d8d116e4cc389dbc23a0055873f",
            "bf27f78edb15477492fb2d5dd8dc5137",
            "ee96a569b8a54944bcac1b1bc164e53e",
            "e556e254882340168833ecf1a7153a90",
            "c077837b8b044c2fb14dcd8fbc44a37b",
            "e5c8b5933c754a1192456f43682276c5",
            "84abf77081a04bb686f794b49e04761d"
          ]
        },
        "id": "6FG8x4i3yZ2B",
        "outputId": "52eb909f-69be-4c80-d9bc-77c2842bf14d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 45.45ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "11368"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_ragas_dataset.to_csv(\"basic_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5I_d_RT_pFr"
      },
      "source": [
        "Evaluar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywp3Rwavy9pc",
        "outputId": "7a3948ce-b743-4d95-a581-17e035215f3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating: 100%|██████████| 63/63 [01:14<00:00,  1.19s/it]\n"
          ]
        }
      ],
      "source": [
        "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4oYnKTn15gY",
        "outputId": "ba48e4d2-5559-4748-8bc6-0101074a5c0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.5000, 'faithfulness': 0.8750, 'answer_relevancy': 0.8866, 'context_recall': 0.9352, 'context_relevancy': 0.2088, 'answer_correctness': 0.4933, 'answer_similarity': 0.9212}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwhBxlxYAdno"
      },
      "source": [
        "### Probando otros recuperadores\n",
        "\n",
        "Podemos probar cómo cambiar nuestro recuperador afecta a la evaluiación.\n",
        "\n",
        "Construiremos esta fábrica de qa_chain simple para crear cadenas de qa_chains estandarizadas donde el único componente diferente será el recuperador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qnfy4VNkzZi2"
      },
      "outputs": [],
      "source": [
        "def create_qa_chain(retriever):\n",
        "  primary_qa_llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature = 0)\n",
        "  created_qa_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever,\n",
        "     \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | RunnablePassthrough.assign(\n",
        "        context = itemgetter(\"context\")\n",
        "      )\n",
        "    | {\n",
        "         \"response\": prompt | primary_qa_llm,\n",
        "         \"context\": itemgetter(\"context\"),\n",
        "      }\n",
        "  )\n",
        "\n",
        "  return created_qa_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOPp4Xq7AvEx"
      },
      "source": [
        "#### Recuperador de documento padre\n",
        "\n",
        "Una de las formas más simples para mejorar un recuperador es embed nuestros documentos en pequeños fragmentos y luego recuperar una cantidad significativa de contexto adicional que \"rodea\" el contexto encontrado.\n",
        "\n",
        "Puedes leer más sobre este método [aquí](https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever).\n",
        "\n",
        "El esquema básico de este método de recuperación es el siguiente:\n",
        "\n",
        "1. Obtener la pregunta del usuario.\n",
        "2. Recuperar documentos secundarios utilizando Dense Vector Retrieval.\n",
        "3. Fusionar los documentos secundarios en función de sus padres. Si tienen los mismos padres, se fusionan.\n",
        "4. Reemplazar los documentos secundarios con sus respectivos documentos padres de una in-memory-store.\n",
        "5. Utilizar los documentos padres para aumentar la generación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "67I6QJAJ0Un7"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "\n",
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500)\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 200)\n",
        "\n",
        "vectorstore = Chroma(collection_name = \"split_parents\", embedding_function = OpenAIEmbeddings())\n",
        "\n",
        "store = InMemoryStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zfk5RYUt00Pw"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = vectorstore,\n",
        "    docstore = store,\n",
        "    child_splitter = child_splitter,\n",
        "    parent_splitter = parent_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "68c1t4o104AK"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(base_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTH0MDolBndm"
      },
      "source": [
        "Crear, probar y luego evaluar nuestra nueva cadena."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KMjLfqOC09Iw"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever_qa_chain = create_qa_chain(parent_document_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Rv8bAHPN1H4P",
        "outputId": "faa6bf43-1604-4468-9faf-bbefd8e48281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Answer: Retrieval-augmented generation (RAG) is a practicable complement to large language models (LLMs) that relies heavily on the relevance of retrieved documents to improve the robustness of generation.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retriever_qa_chain.invoke({\"question\": \"What is RAG?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQJRIQmU1WTw",
        "outputId": "295a9011-684d-4c38-e409-867022603608"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:20<00:00,  2.30s/it]\n"
          ]
        }
      ],
      "source": [
        "pdr_qa_ragas_dataset = create_ragas_dataset(parent_document_retriever_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bf7f045bdbe24360ad2aa2f4c8f02e79",
            "761e3c6035bf49429b3035145451d2df",
            "ffb7c97e7af648aaa13a43427154140e",
            "95d92c5c74e845779337eb727c2bbfc0",
            "6e7fb9a1d1454fcd9bcf5b5f748fb975",
            "207785da1f404d6ea0e8c63655a7aa51",
            "71237d176b2c4138a5e0346d10482257",
            "ed457547dc154f6bbce4ec970bb09c76",
            "c9f479f81119450bb451d5830361467c",
            "56098a347ea94ea3b10bd8d2ec0d4288",
            "7940d9e3f5fa4592b58dec3fdb55595a"
          ]
        },
        "id": "d9vfKnCL1jtB",
        "outputId": "1d7421a8-b564-4da3-cd74-d1eb3f8311f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 330.52ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "45260"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_ragas_dataset.to_csv(\"pdr_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfB1H9S_1mW3",
        "outputId": "426d7b1b-2b0c-40d3-e7d7-39da43363f06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating: 100%|██████████| 63/63 [00:50<00:00,  1.26it/s]\n"
          ]
        }
      ],
      "source": [
        "pdr_qa_result = evaluate_ragas_dataset(pdr_qa_ragas_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nFyYCdL2Nco",
        "outputId": "bdde7173-c649-40bc-cbc3-e38a70c9f50a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.8951, 'faithfulness': 0.9444, 'answer_relevancy': 0.9590, 'context_recall': 0.9722, 'context_relevancy': 0.0275, 'answer_correctness': 0.5036, 'answer_similarity': 0.9386}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaNk6o7_BqX8"
      },
      "source": [
        "#### Ensemble Retrieval\n",
        "\n",
        "Puedes leer más sobre esto [aquí](https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble)!\n",
        "\n",
        "La idea básica es la siguiente:\n",
        "\n",
        "1. Obtener la pregunta del usuario.\n",
        "2. Utilizar el par de recuperadores:\n",
        "    - Recuperar documentos con Recuperación de Vector Esparsa BM25\n",
        "    - Recuperar documentos con un Método de Recuperación de Vector Denso\n",
        "3. Recopilar y \"fusionar\" los documentos recuperados en función de su ponderación utilizando el algoritmo [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) en una sola lista clasificada.\n",
        "4. Utilizar esos documentos para aumentar nuestra generación.\n",
        "\n",
        "¡Asegúrate de que tu lista de `weights` - la ponderación relativa de cada recuperador - sume 1!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "zz7dl1GD5-L-"
      },
      "outputs": [],
      "source": [
        "%pip install rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Vs8wxT9b5pRA"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 450, chunk_overlap = 75)\n",
        "docs = text_splitter.split_documents(base_docs)\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(docs)\n",
        "bm25_retriever.k = 2\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(docs, embedding)\n",
        "chroma_retriever = vectorstore.as_retriever(search_kwargs = {\"k\": 3})\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(retrievers = [bm25_retriever, chroma_retriever], weights = [0.75, 0.25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cv69YDpF6PrJ"
      },
      "outputs": [],
      "source": [
        "ensemble_retriever_qa_chain = create_qa_chain(ensemble_retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6lSszzrf6UmP",
        "outputId": "8a5893d5-4095-42e5-aecf-66d849512321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'RAG stands for Retrieval Augmented Generation.'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retriever_qa_chain.invoke({\"question\": \"What is RAG?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abUgTGDT6UrV",
        "outputId": "749ae6db-75b9-48a7-e743-a8aecdcbd802"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [00:18<00:00,  2.06s/it]\n"
          ]
        }
      ],
      "source": [
        "ensemble_qa_ragas_dataset = create_ragas_dataset(ensemble_retriever_qa_chain, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "632135599e39470aac1a3bb3d3de0ca4",
            "567176b50d074a1c9d384a8df8c3ff4c",
            "6bfa39f2c84e4f08b5ffb9a416398824",
            "911b40169865413b98643789150e5495",
            "2add9d30edd84152bb6d7bfa4ed2d910",
            "f34ffd11b98045b9bae326dd48a54896",
            "e3e19fc9963c4bf39293bda7c2030d5a",
            "c15c27b0523a429e9d77f439d47ada90",
            "256a0dbb2f104d928e181d2a882a9867",
            "68790cfe4ea14fc4a63275f3e99c468f",
            "e7df092ac205443e8baa3646ff1eae5b"
          ]
        },
        "id": "bGHipYsf7phk",
        "outputId": "a70b0d3e-870f-49b8-a16a-5b7d4623c33f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 330.78ba/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "21354"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_ragas_dataset.to_csv(\"ensemble_qa_ragas_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozo0jkvx7r1d",
        "outputId": "f5770c52-4614-4172-8834-d48bd4005218"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
            "Evaluating: 100%|██████████| 63/63 [02:01<00:00,  1.93s/it]\n"
          ]
        }
      ],
      "source": [
        "ensemble_qa_result = evaluate_ragas_dataset(ensemble_qa_ragas_dataset)\n",
        "\n",
        "# A veces causa problemas, ejecutarlo hasta que funcione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvabdcbh793a",
        "outputId": "56daa44b-841b-4924-9242-77c2bc93f86e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.6755, 'faithfulness': 1.0000, 'answer_relevancy': 0.9949, 'context_recall': 0.9167, 'context_relevancy': 0.1470, 'answer_correctness': 0.5536, 'answer_similarity': 0.9425}"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4vXVWqiCcSI"
      },
      "source": [
        "### Conclusión\n",
        "\n",
        "Observar resultados en una tabla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmBoVQ5hV3Kc",
        "outputId": "12196187-5cbf-40b2-f35f-ab45616e71a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.5000, 'faithfulness': 0.8750, 'answer_relevancy': 0.8866, 'context_recall': 0.9352, 'context_relevancy': 0.2088, 'answer_correctness': 0.4933, 'answer_similarity': 0.9212}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basic_qa_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax1JLXKxUsXF",
        "outputId": "b83ba792-7e66-44ff-b219-0f3890a5fe8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.8951, 'faithfulness': 0.9444, 'answer_relevancy': 0.9590, 'context_recall': 0.9722, 'context_relevancy': 0.0275, 'answer_correctness': 0.5036, 'answer_similarity': 0.9386}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdr_qa_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drxLlO3zUpyQ",
        "outputId": "3b595607-2fa5-4590-d2e6-9707aa7bb283"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_precision': 0.6755, 'faithfulness': 1.0000, 'answer_relevancy': 0.9949, 'context_recall': 0.9167, 'context_relevancy': 0.1470, 'answer_correctness': 0.5536, 'answer_similarity': 0.9425}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6YPGf-2l0Kx"
      },
      "source": [
        "Podemos ampliar cada resultado y encontrar información específica sobre cada una de las preguntas y respuestas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "SkxLtk43ikka"
      },
      "outputs": [],
      "source": [
        "ensemble_qa_result_df = ensemble_qa_result.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3JZMhUg3jSvE",
        "outputId": "95d1cf44-88ee-4056-b698-64237b119fe0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truths</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_relevancy</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>answer_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What does this paper aim to conduct a survey a...</td>\n",
              "      <td>Answer: This paper aims to conduct a survey ab...</td>\n",
              "      <td>[attracted increasing attention of the compu-\\...</td>\n",
              "      <td>[This paper aims to conduct a survey about ret...</td>\n",
              "      <td>This paper aims to conduct a survey about retr...</td>\n",
              "      <td>0.804167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.967399</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.540072</td>\n",
              "      <td>0.960286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the main focus of the paper 'A Survey ...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>[The main focus of the paper 'A Survey on Retr...</td>\n",
              "      <td>The main focus of the paper 'A Survey on Retri...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.621921</td>\n",
              "      <td>0.987620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the aim of this paper?</td>\n",
              "      <td>The aim of this paper is to propose Corrective...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The aim of this paper is to conduct a compreh...</td>\n",
              "      <td>The aim of this paper is to conduct a comprehe...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.989808</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.596534</td>\n",
              "      <td>0.886143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the aim of this paper?</td>\n",
              "      <td>The aim of this paper is to propose Corrective...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The aim of this paper is to conduct a survey ...</td>\n",
              "      <td>The aim of this paper is to conduct a survey a...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.996603</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.472811</td>\n",
              "      <td>0.891278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the focus of this paper?</td>\n",
              "      <td>The focus of this paper is to improve the robu...</td>\n",
              "      <td>[and main intent within questions.\\nquestion: ...</td>\n",
              "      <td>[The focus of this paper is on retrieval-augme...</td>\n",
              "      <td>The focus of this paper is on retrieval-augmen...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.433662</td>\n",
              "      <td>0.877506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What are the advantages of retrieval-augmented...</td>\n",
              "      <td>Advantages of retrieval-augmented text generat...</td>\n",
              "      <td>[attracted increasing attention of the compu-\\...</td>\n",
              "      <td>[The advantages of retrieval-augmented text ge...</td>\n",
              "      <td>The advantages of retrieval-augmented text gen...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.576429</td>\n",
              "      <td>0.972384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What are the advantages of retrieval-augmented...</td>\n",
              "      <td>Advantages of retrieval-augmented text generat...</td>\n",
              "      <td>[attracted increasing attention of the compu-\\...</td>\n",
              "      <td>[The advantages of retrieval-augmented text ge...</td>\n",
              "      <td>The advantages of retrieval-augmented text gen...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.574617</td>\n",
              "      <td>0.965136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What are the advantages of retrieval-augmented...</td>\n",
              "      <td>Advantages of retrieval-augmented text generat...</td>\n",
              "      <td>[attracted increasing attention of the compu-\\...</td>\n",
              "      <td>[Retrieval-augmented text generation models ha...</td>\n",
              "      <td>Retrieval-augmented text generation models hav...</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>0.470002</td>\n",
              "      <td>0.956948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the focus of the paper 'A Survey on Re...</td>\n",
              "      <td>The focus of the paper 'A Survey on Retrieval-...</td>\n",
              "      <td>[A Survey on Retrieval-Augmented Text Generati...</td>\n",
              "      <td>[The focus of the paper 'A Survey on Retrieval...</td>\n",
              "      <td>The focus of the paper 'A Survey on Retrieval-...</td>\n",
              "      <td>0.679167</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.016949</td>\n",
              "      <td>0.696202</td>\n",
              "      <td>0.984808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What does this paper aim to conduct a survey a...   \n",
              "1  What is the main focus of the paper 'A Survey ...   \n",
              "2                     What is the aim of this paper?   \n",
              "3                     What is the aim of this paper?   \n",
              "4                   What is the focus of this paper?   \n",
              "5  What are the advantages of retrieval-augmented...   \n",
              "6  What are the advantages of retrieval-augmented...   \n",
              "7  What are the advantages of retrieval-augmented...   \n",
              "8  What is the focus of the paper 'A Survey on Re...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Answer: This paper aims to conduct a survey ab...   \n",
              "1  The main focus of the paper 'A Survey on Retri...   \n",
              "2  The aim of this paper is to propose Corrective...   \n",
              "3  The aim of this paper is to propose Corrective...   \n",
              "4  The focus of this paper is to improve the robu...   \n",
              "5  Advantages of retrieval-augmented text generat...   \n",
              "6  Advantages of retrieval-augmented text generat...   \n",
              "7  Advantages of retrieval-augmented text generat...   \n",
              "8  The focus of the paper 'A Survey on Retrieval-...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [attracted increasing attention of the compu-\\...   \n",
              "1  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "2  [and main intent within questions.\\nquestion: ...   \n",
              "3  [and main intent within questions.\\nquestion: ...   \n",
              "4  [and main intent within questions.\\nquestion: ...   \n",
              "5  [attracted increasing attention of the compu-\\...   \n",
              "6  [attracted increasing attention of the compu-\\...   \n",
              "7  [attracted increasing attention of the compu-\\...   \n",
              "8  [A Survey on Retrieval-Augmented Text Generati...   \n",
              "\n",
              "                                       ground_truths  \\\n",
              "0  [This paper aims to conduct a survey about ret...   \n",
              "1  [The main focus of the paper 'A Survey on Retr...   \n",
              "2  [The aim of this paper is to conduct a compreh...   \n",
              "3  [The aim of this paper is to conduct a survey ...   \n",
              "4  [The focus of this paper is on retrieval-augme...   \n",
              "5  [The advantages of retrieval-augmented text ge...   \n",
              "6  [The advantages of retrieval-augmented text ge...   \n",
              "7  [Retrieval-augmented text generation models ha...   \n",
              "8  [The focus of the paper 'A Survey on Retrieval...   \n",
              "\n",
              "                                        ground_truth  context_precision  \\\n",
              "0  This paper aims to conduct a survey about retr...           0.804167   \n",
              "1  The main focus of the paper 'A Survey on Retri...           0.679167   \n",
              "2  The aim of this paper is to conduct a comprehe...           0.000000   \n",
              "3  The aim of this paper is to conduct a survey a...           0.000000   \n",
              "4  The focus of this paper is on retrieval-augmen...           1.000000   \n",
              "5  The advantages of retrieval-augmented text gen...           1.000000   \n",
              "6  The advantages of retrieval-augmented text gen...           1.000000   \n",
              "7  Retrieval-augmented text generation models hav...           0.916667   \n",
              "8  The focus of the paper 'A Survey on Retrieval-...           0.679167   \n",
              "\n",
              "   faithfulness  answer_relevancy  context_recall  context_relevancy  \\\n",
              "0           1.0          0.967399            0.25           0.400000   \n",
              "1           1.0          1.000000            1.00           0.111111   \n",
              "2           1.0          0.989808            1.00           0.088889   \n",
              "3           1.0          0.996603            1.00           0.088889   \n",
              "4           1.0          1.000000            1.00           0.155556   \n",
              "5           1.0          1.000000            1.00           0.153846   \n",
              "6           1.0          1.000000            1.00           0.153846   \n",
              "7           1.0          1.000000            1.00           0.153846   \n",
              "8           1.0          1.000000            1.00           0.016949   \n",
              "\n",
              "   answer_correctness  answer_similarity  \n",
              "0            0.540072           0.960286  \n",
              "1            0.621921           0.987620  \n",
              "2            0.596534           0.886143  \n",
              "3            0.472811           0.891278  \n",
              "4            0.433662           0.877506  \n",
              "5            0.576429           0.972384  \n",
              "6            0.574617           0.965136  \n",
              "7            0.470002           0.956948  \n",
              "8            0.696202           0.984808  "
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_qa_result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jXR7ckel-v8"
      },
      "source": [
        "Examinaremos cómo combinar los resultados y visualizarlos en una tabla única para poder hacer inferencias sobre ellos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "BE5KKE_JkcD3"
      },
      "outputs": [],
      "source": [
        "def create_df_dict(pipeline_name, pipeline_items):\n",
        "  df_dict = {\"name\": pipeline_name}\n",
        "  for name, score in pipeline_items:\n",
        "    df_dict[name] = score\n",
        "  return df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "L1mPqYdqk4iQ"
      },
      "outputs": [],
      "source": [
        "basic_rag_df_dict = create_df_dict(\"basic_rag\", basic_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ntJPzwy9lI46"
      },
      "outputs": [],
      "source": [
        "pdr_rag_df_dict = create_df_dict(\"pdr_rag\", pdr_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "R0fkbIQElPza"
      },
      "outputs": [],
      "source": [
        "ensemble_rag_df_dict = create_df_dict(\"ensemble_rag\", ensemble_qa_result.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Bc4T1E83lVbE"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame([basic_rag_df_dict, pdr_rag_df_dict, ensemble_rag_df_dict])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "cv_9wNYGlibg",
        "outputId": "6580c17c-543a-4d54-8577-104c0173f368"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_relevancy</th>\n",
              "      <th>answer_correctness</th>\n",
              "      <th>answer_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ensemble_rag</td>\n",
              "      <td>0.675463</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994868</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.146992</td>\n",
              "      <td>0.553583</td>\n",
              "      <td>0.942457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pdr_rag</td>\n",
              "      <td>0.895062</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.959008</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.027478</td>\n",
              "      <td>0.503580</td>\n",
              "      <td>0.938622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>basic_rag</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.886624</td>\n",
              "      <td>0.935185</td>\n",
              "      <td>0.208810</td>\n",
              "      <td>0.493326</td>\n",
              "      <td>0.921228</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name  context_precision  faithfulness  answer_relevancy  \\\n",
              "2  ensemble_rag           0.675463      1.000000          0.994868   \n",
              "1       pdr_rag           0.895062      0.944444          0.959008   \n",
              "0     basic_rag           0.500000      0.875000          0.886624   \n",
              "\n",
              "   context_recall  context_relevancy  answer_correctness  answer_similarity  \n",
              "2        0.916667           0.146992            0.553583           0.942457  \n",
              "1        0.972222           0.027478            0.503580           0.938622  \n",
              "0        0.935185           0.208810            0.493326           0.921228  "
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df.sort_values(\"answer_correctness\", ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fbhz-vD4JPtN"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'itemgetter' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableParallel\n\u001b[0;32m      3\u001b[0m retrieval_augmented_qa_chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      4\u001b[0m     RunnableParallel({\n\u001b[1;32m----> 5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mitemgetter\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is RAG?\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m|\u001b[39m base_retriever,\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: RunnablePassthrough()\n\u001b[0;32m      7\u001b[0m     }) \u001b[38;5;241m|\u001b[39m {\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt \u001b[38;5;241m|\u001b[39m primary_qa_llm \u001b[38;5;241m|\u001b[39m parser,\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: itemgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'itemgetter' is not defined"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    RunnableParallel({\n",
        "        'context': itemgetter('question') | base_retriever,\n",
        "        'question': RunnablePassthrough()\n",
        "    }) | {\n",
        "        'response': prompt | primary_qa_llm | parser,\n",
        "        'context': itemgetter('context')\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fff4a6672c848a38945e19101c46168": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d17b8847ab34a1d8fc79430e8b64a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c8b5933c754a1192456f43682276c5",
            "placeholder": "​",
            "style": "IPY_MODEL_84abf77081a04bb686f794b49e04761d",
            "value": " 1/1 [00:00&lt;00:00, 35.79ba/s]"
          }
        },
        "207785da1f404d6ea0e8c63655a7aa51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fc25617c664e4aa02b7457832c1bef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256a0dbb2f104d928e181d2a882a9867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2add9d30edd84152bb6d7bfa4ed2d910": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31390facfbeb455fa83067fc23d30718": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5367cbe7ca4d43b089ff0d5d7cd17d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53ebcf672a244978391cae559db5bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_f2de6a2c1f4b4a2fa5196028c0da0754",
            "value": " 1/1 [00:00&lt;00:00, 18.79ba/s]"
          }
        },
        "56098a347ea94ea3b10bd8d2ec0d4288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567176b50d074a1c9d384a8df8c3ff4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34ffd11b98045b9bae326dd48a54896",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e19fc9963c4bf39293bda7c2030d5a",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "632135599e39470aac1a3bb3d3de0ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_567176b50d074a1c9d384a8df8c3ff4c",
              "IPY_MODEL_6bfa39f2c84e4f08b5ffb9a416398824",
              "IPY_MODEL_911b40169865413b98643789150e5495"
            ],
            "layout": "IPY_MODEL_2add9d30edd84152bb6d7bfa4ed2d910"
          }
        },
        "65f75f3d72cd415faffb32999893738d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fff4a6672c848a38945e19101c46168",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de662cb67d054f08a15d191923d40369",
            "value": 1
          }
        },
        "68790cfe4ea14fc4a63275f3e99c468f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfa39f2c84e4f08b5ffb9a416398824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15c27b0523a429e9d77f439d47ada90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_256a0dbb2f104d928e181d2a882a9867",
            "value": 1
          }
        },
        "6e7fb9a1d1454fcd9bcf5b5f748fb975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71237d176b2c4138a5e0346d10482257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "761e3c6035bf49429b3035145451d2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207785da1f404d6ea0e8c63655a7aa51",
            "placeholder": "​",
            "style": "IPY_MODEL_71237d176b2c4138a5e0346d10482257",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "7940d9e3f5fa4592b58dec3fdb55595a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84abf77081a04bb686f794b49e04761d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86761a36bdb04fed9f1dae6e74da54ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e079c0eb3d9c4ae3a40491f059a864f7",
              "IPY_MODEL_d4bde97f3895450782030cad7808ea59",
              "IPY_MODEL_1d17b8847ab34a1d8fc79430e8b64a12"
            ],
            "layout": "IPY_MODEL_fb953d8d116e4cc389dbc23a0055873f"
          }
        },
        "911b40169865413b98643789150e5495": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68790cfe4ea14fc4a63275f3e99c468f",
            "placeholder": "​",
            "style": "IPY_MODEL_e7df092ac205443e8baa3646ff1eae5b",
            "value": " 1/1 [00:00&lt;00:00, 33.41ba/s]"
          }
        },
        "95d92c5c74e845779337eb727c2bbfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56098a347ea94ea3b10bd8d2ec0d4288",
            "placeholder": "​",
            "style": "IPY_MODEL_7940d9e3f5fa4592b58dec3fdb55595a",
            "value": " 1/1 [00:00&lt;00:00, 33.86ba/s]"
          }
        },
        "b4a71cf676584200b46922fb976d1d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fc25617c664e4aa02b7457832c1bef",
            "placeholder": "​",
            "style": "IPY_MODEL_b556054df18d47aa8cb58ac482ca31bb",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "b53ebcf672a244978391cae559db5bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b556054df18d47aa8cb58ac482ca31bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf27f78edb15477492fb2d5dd8dc5137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7f045bdbe24360ad2aa2f4c8f02e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_761e3c6035bf49429b3035145451d2df",
              "IPY_MODEL_ffb7c97e7af648aaa13a43427154140e",
              "IPY_MODEL_95d92c5c74e845779337eb727c2bbfc0"
            ],
            "layout": "IPY_MODEL_6e7fb9a1d1454fcd9bcf5b5f748fb975"
          }
        },
        "c077837b8b044c2fb14dcd8fbc44a37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c15c27b0523a429e9d77f439d47ada90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4bc64d47f2e4a239cf7156e7812887d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4a71cf676584200b46922fb976d1d50",
              "IPY_MODEL_65f75f3d72cd415faffb32999893738d",
              "IPY_MODEL_5367cbe7ca4d43b089ff0d5d7cd17d3c"
            ],
            "layout": "IPY_MODEL_31390facfbeb455fa83067fc23d30718"
          }
        },
        "c9f479f81119450bb451d5830361467c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4bde97f3895450782030cad7808ea59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e556e254882340168833ecf1a7153a90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c077837b8b044c2fb14dcd8fbc44a37b",
            "value": 1
          }
        },
        "de662cb67d054f08a15d191923d40369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e079c0eb3d9c4ae3a40491f059a864f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf27f78edb15477492fb2d5dd8dc5137",
            "placeholder": "​",
            "style": "IPY_MODEL_ee96a569b8a54944bcac1b1bc164e53e",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "e3e19fc9963c4bf39293bda7c2030d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e556e254882340168833ecf1a7153a90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c8b5933c754a1192456f43682276c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7df092ac205443e8baa3646ff1eae5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed457547dc154f6bbce4ec970bb09c76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee96a569b8a54944bcac1b1bc164e53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2de6a2c1f4b4a2fa5196028c0da0754": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f34ffd11b98045b9bae326dd48a54896": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb953d8d116e4cc389dbc23a0055873f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb7c97e7af648aaa13a43427154140e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed457547dc154f6bbce4ec970bb09c76",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9f479f81119450bb451d5830361467c",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
